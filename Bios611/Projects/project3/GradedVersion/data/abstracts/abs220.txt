JMIR Hum Factors. 2018 Jul 16;5(3):e10070. doi: 10.2196/10070.
Software for Administering the National Cancer Institute's Patient-ReportedOutcomes Version of the Common Terminology Criteria for Adverse Events: UsabilityStudy.
Schoen MW(1), Basch E(2)(3)(4)(5), Hudson LL(6), Chung AE(4)(7)(8), MendozaTR(9), Mitchell SA(10), St Germain D(11), Baumgartner P(12), Sit L(3), RogakLJ(3), Shouery M(3), Shalley E(13), Reeve BB(14), Fawzy MR(15), Bhavsar NA(16),Cleeland C(9), Schrag D(17), Dueck AC(18), Abernethy AP(6)(14)(19).
Author information:(1)Division of Hematology and Medical Oncology, Department of Internal Medicine,Saint Louis University School of Medicine, Saint Louis, MO, United States.(2)Division of Hematology/Oncology, Department of Medicine, University of NorthCarolina School of Medicine, Chapel Hill, NC, United States.(3)Department of Epidemiology and Biostatistics, Memorial Sloan Kettering CancerCenter, New York, NY, United States.(4)Lineberger Comprehensive Cancer Center, University of North Carolina, ChapelHill, NC, United States.(5)Department of Health Policy and Management, Gillings School of Public Health,University of North Carolina, Chapel Hill, NC, United States.(6)Duke Clinical Research Institute, Duke University, Durham, NC, United States.(7)Division of General Medicine and Clinical Epidemiology, Department ofMedicine, University of North Carolina School of Medicine, Chapel Hill, NC,United States.(8)Division of General Pediatrics & Adolescent Medicine, Department ofPediatrics, Program on Health & Clinical Informatics, University of NorthCarolina School of Medicine, Chapel Hill, NC, United States.(9)Department of Symptom Research, The University of Texas MD Anderson CancerCenter, Houston, TX, United States.(10)Division of Cancer Control and Population Sciences, National CancerInstitute, Rockville, MD, United States.(11)Division of Cancer Prevention, National Cancer Institute, Rockville, MD,United States.(12)SemanticBits, Herndon, VA, United States.(13)Center for Biomedical Informatics and Information Technology, National CancerInstitute, Rockville, MD, United States.(14)Duke Cancer Institute, Durham, NC, United States.(15)FHI 360, Durham, NC, United States.(16)Division of General Internal Medicine, Duke University School of Medicine,Durham, NC, United States.(17)Division of Population Sciences, Dana-Farber Cancer Institute, Boston, MA,United States.(18)Alliance Statistics and Data Center, Mayo Clinic, Scottsdale, AZ, UnitedStates.(19)Flatiron Health, New York, NY, United States.
BACKGROUND: The US National Cancer Institute (NCI) developed software to gathersymptomatic adverse events directly from patients participating in clinicaltrials. The software administers surveys to patients using items from thePatient-Reported Outcomes version of the Common Terminology Criteria for AdverseEvents (PRO-CTCAE) through Web-based or automated telephone interfaces andfacilitates the management of survey administration and the resultant data byprofessionals (clinicians and research associates).OBJECTIVE: The purpose of this study was to iteratively evaluate and improve theusability of the PRO-CTCAE software.METHODS: Heuristic evaluation of the software functionality was followed bysemiscripted, think-aloud protocols in two consecutive rounds of usabilitytesting among patients with cancer, clinicians, and research associates at 3cancer centers. We conducted testing with patients both in clinics and at home(remotely) for both Web-based and telephone interfaces. Furthermore, we refinedthe software between rounds and retested.RESULTS: Heuristic evaluation identified deviations from the best practicesacross 10 standardized categories, which informed initial software improvement.Subsequently, we conducted user-based testing among 169 patients and 47professionals. Software modifications between rounds addressed identified issues,including difficulty using radio buttons, absence of survey progress indicators,and login problems (for patients) as well as scheduling of patient surveys (forprofessionals). The initial System Usability Scale (SUS) score for the patientWeb-based interface was 86 and 82 (P=.22) before and after modifications,respectively, whereas the task completion score was 4.47, which improved to 4.58(P=.39) after modifications. Following modifications for professional users, theSUS scores improved from 71 to 75 (P=.47), and the mean task performance improvedsignificantly (4.40 vs 4.02; P=.001).CONCLUSIONS: Software modifications, informed by rigorous assessment, rendered ausable system, which is currently used in multiple NCI-sponsored multicentercancer clinical trials.TRIAL REGISTRATION: ClinicalTrials.gov NCT01031641;https://clinicaltrials.gov/ct2/show/NCT01031641 (Archived by WebCite athttp://www.webcitation.org/708hTjlTl).
Â©Martin W Schoen, Ethan Basch, Lori L Hudson, Arlene E Chung, Tito R Mendoza,Sandra A Mitchell, Diane St. Germain, Paul Baumgartner, Laura Sit, Lauren JRogak, Marwan Shouery, Eve Shalley, Bryce B Reeve, Maria R Fawzy, Nrupen ABhavsar, Charles Cleeland, Deborah Schrag, Amylou C Dueck, Amy P Abernethy.Originally published in JMIR Human Factors (http://humanfactors.jmir.org),16.07.2018.
